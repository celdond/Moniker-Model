{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import torch\n",
    "import os\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, set_seed, get_linear_schedule_with_warmup\n",
    "from tqdm import tqdm, trange\n",
    "import transformers\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/goodreads_books.csv\", converters={'COLUMN_NAME': pd.eval})\n",
    "data = data.sample(n = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.filter([\"title\", \"rating_count\", \"average_rating\", \"genre_and_votes\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genre_break(genre):\n",
    "    for index, item in enumerate(genre):\n",
    "        new_item = re.sub('\\s[0-9]+', '', item)\n",
    "        genre[index] = new_item\n",
    "    \n",
    "    return genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"genre\"] = data[\"genre_and_votes\"].str.split(\", \")\n",
    "data.drop(axis=1, columns=[\"genre_and_votes\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(inplace=True, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 947 entries, 33901 to 36835\n",
      "Data columns (total 4 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   title           947 non-null    object \n",
      " 1   rating_count    947 non-null    int64  \n",
      " 2   average_rating  947 non-null    float64\n",
      " 3   genre           947 non-null    object \n",
      "dtypes: float64(1), int64(1), object(2)\n",
      "memory usage: 37.0+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33901    [Fantasy, Childrens-Middle Grade, Childrens, A...\n",
       "35383                                            [Romance]\n",
       "35418                [Contemporary, Retellings, Childrens]\n",
       "27807    [Romance-Paranormal Romance, Paranormal-Vampir...\n",
       "41157    [Travel, Nonfiction, Autobiography-Memoir, Cul...\n",
       "                               ...                        \n",
       "50474          [Classics, Mystery, Fiction, Short Stories]\n",
       "11804    [Fantasy, European Literature-Czech Literature...\n",
       "18063    [Fiction, Contemporary, European Literature-Ge...\n",
       "11346                                          [Christian]\n",
       "36835           [Short Stories, Fiction, Literary Fiction]\n",
       "Name: genre, Length: 947, dtype: object"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"genre\"].apply(lambda item: genre_break(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>rating_count</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33901</th>\n",
       "      <td>Switch</td>\n",
       "      <td>2163</td>\n",
       "      <td>4.10</td>\n",
       "      <td>[Fantasy, Childrens-Middle Grade, Childrens, A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35383</th>\n",
       "      <td>Until Forever</td>\n",
       "      <td>465</td>\n",
       "      <td>4.69</td>\n",
       "      <td>[Romance]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35418</th>\n",
       "      <td>Looking-Glass Girl</td>\n",
       "      <td>881</td>\n",
       "      <td>4.23</td>\n",
       "      <td>[Contemporary, Retellings, Childrens]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27807</th>\n",
       "      <td>Because Your Vampire Said So</td>\n",
       "      <td>4530</td>\n",
       "      <td>4.08</td>\n",
       "      <td>[Romance-Paranormal Romance, Paranormal-Vampir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41157</th>\n",
       "      <td>Beyond the Sky and the Earth: A Journey Into B...</td>\n",
       "      <td>3383</td>\n",
       "      <td>4.15</td>\n",
       "      <td>[Travel, Nonfiction, Autobiography-Memoir, Cul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50474</th>\n",
       "      <td>The Complete Sherlock Holmes, Volume I</td>\n",
       "      <td>28906</td>\n",
       "      <td>4.49</td>\n",
       "      <td>[Classics, Mystery, Fiction, Short Stories]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11804</th>\n",
       "      <td>VlÃ¡dci strachu</td>\n",
       "      <td>663</td>\n",
       "      <td>4.23</td>\n",
       "      <td>[Fantasy, European Literature-Czech Literature...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18063</th>\n",
       "      <td>Vom Ende der Einsamkeit</td>\n",
       "      <td>9687</td>\n",
       "      <td>4.27</td>\n",
       "      <td>[Fiction, Contemporary, European Literature-Ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11346</th>\n",
       "      <td>What Gets You Through</td>\n",
       "      <td>23</td>\n",
       "      <td>4.43</td>\n",
       "      <td>[Christian]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36835</th>\n",
       "      <td>A Permanent Member of the Family</td>\n",
       "      <td>1289</td>\n",
       "      <td>3.59</td>\n",
       "      <td>[Short Stories, Fiction, Literary Fiction]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>947 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  rating_count  \\\n",
       "33901                                             Switch          2163   \n",
       "35383                                      Until Forever           465   \n",
       "35418                                 Looking-Glass Girl           881   \n",
       "27807                       Because Your Vampire Said So          4530   \n",
       "41157  Beyond the Sky and the Earth: A Journey Into B...          3383   \n",
       "...                                                  ...           ...   \n",
       "50474             The Complete Sherlock Holmes, Volume I         28906   \n",
       "11804                                    VlÃ¡dci strachu           663   \n",
       "18063                            Vom Ende der Einsamkeit          9687   \n",
       "11346                              What Gets You Through            23   \n",
       "36835                   A Permanent Member of the Family          1289   \n",
       "\n",
       "       average_rating                                              genre  \n",
       "33901            4.10  [Fantasy, Childrens-Middle Grade, Childrens, A...  \n",
       "35383            4.69                                          [Romance]  \n",
       "35418            4.23              [Contemporary, Retellings, Childrens]  \n",
       "27807            4.08  [Romance-Paranormal Romance, Paranormal-Vampir...  \n",
       "41157            4.15  [Travel, Nonfiction, Autobiography-Memoir, Cul...  \n",
       "...               ...                                                ...  \n",
       "50474            4.49        [Classics, Mystery, Fiction, Short Stories]  \n",
       "11804            4.23  [Fantasy, European Literature-Czech Literature...  \n",
       "18063            4.27  [Fiction, Contemporary, European Literature-Ge...  \n",
       "11346            4.43                                        [Christian]  \n",
       "36835            3.59         [Short Stories, Fiction, Literary Fiction]  \n",
       "\n",
       "[947 rows x 4 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tuning Set-Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BookTitles(Dataset):\n",
    "    def __init__(self, content, gpt2_type=\"gpt2\", max_length=256):\n",
    "\n",
    "        self.tokenizer = GPT2Tokenizer.from_pretrained(gpt2_type, bos_token = '<startoftext>', eos_token = '<endoftext>', pad_token = '<pad>')\n",
    "        self.input_ids = []\n",
    "\n",
    "        for _, row in content.iterrows():\n",
    "          tags = \"\"\n",
    "          for item in row[3]:\n",
    "              tags = tags + item + ', '\n",
    "          prep = self.tokenizer.encode(f'<startoftext>Tags: {tags}\\nTitle: {row[0]}<endoftext>', truncation = True, max_length = max_length, padding=\"max_length\")\n",
    "          self.input_ids.append(torch.tensor(prep))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.input_ids[item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pack_tensor(new_tensor, packed_tensor, max_seq_len):\n",
    "    if packed_tensor is None:\n",
    "        return new_tensor, True, None\n",
    "    if new_tensor.size()[1] + packed_tensor.size()[1] > max_seq_len:\n",
    "        return packed_tensor, False, new_tensor\n",
    "    else:\n",
    "        packed_tensor = torch.cat([new_tensor, packed_tensor[:, 1:]], dim=1)\n",
    "        return packed_tensor, True, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    dataset, model, tokenizer,\n",
    "    batch_size=16, epochs=4, lr=2e-5,\n",
    "    max_seq_len=400, warmup_steps=200,\n",
    "    gpt2_type=\"gpt2\", output_dir=\".\", output_prefix=\"wreckgar\",\n",
    "    test_mode=False, save_model_on_epoch=False,\n",
    "):\n",
    "    acc_steps = 100\n",
    "    device = torch.device(\"cuda\")\n",
    "    model = model.cuda()\n",
    "    model.train()\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer, num_warmup_steps=warmup_steps, num_training_steps=-1\n",
    "    )\n",
    "\n",
    "    train_dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "    loss=0\n",
    "    accumulating_batch_count = 0\n",
    "    input_tensor = None\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        print(f\"Training epoch {epoch}\")\n",
    "        print(loss)\n",
    "        for idx, entry in tqdm(enumerate(train_dataloader)):\n",
    "            (input_tensor, carry_on, remainder) = pack_tensor(entry, input_tensor, 768)\n",
    "\n",
    "            if carry_on and idx != len(train_dataloader) - 1:\n",
    "                continue\n",
    "\n",
    "            input_tensor = input_tensor.to(device)\n",
    "            outputs = model(input_tensor, labels=input_tensor)\n",
    "            loss = outputs[0]\n",
    "            loss.backward()\n",
    "\n",
    "            if (accumulating_batch_count % batch_size) == 0:\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "                optimizer.zero_grad()\n",
    "                model.zero_grad()\n",
    "\n",
    "            accumulating_batch_count += 1\n",
    "            input_tensor = None\n",
    "        if save_model_on_epoch:\n",
    "            torch.save(\n",
    "                model.state_dict(),\n",
    "                os.path.join(output_dir, f\"{output_prefix}-{epoch}.pt\"),\n",
    "            )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "train_set = BookTitles(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Set-Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 50260. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(50260, 768)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(32)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2', bos_token = '<startoftext>', eos_token = '<endoftext>', pad_token = '<pad>')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2', pad_token_id = tokenizer.eos_token_id).cuda()\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 0\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "947it [12:13,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 1\n",
      "tensor(9.1137, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "947it [12:34,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 2\n",
      "tensor(5.3341, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "947it [12:42,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 3\n",
      "tensor(2.9886, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "947it [12:55,  1.22it/s]\n"
     ]
    }
   ],
   "source": [
    "model = train(train_set, model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Tags: Romance, \\nTitle: Hi\"\n",
    "encoded_input = tokenizer.encode(f'{text}', return_tensors='pt').to(\"cuda\")\n",
    "outputs = model.generate(encoded_input, max_length = 128, no_repeat_ngram_size = 2, num_beams = 5, early_stopping = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tags: Romance, \n",
      "Title: Hi,\n",
      "\n",
      "I I,,\n",
      "I, I, my.. I'm..,.,., my.,\n",
      "I,\" I., I,\"I'm, the.\" I.\".,.\",I,\" my.., the,\".,\" I,\" I.,\" the my,\"the\",\",the,\",\". I.\"I.,,\".,\" my.\",\".\" the,\".,, a, an,\" a,\"\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(outputs[0], skip_special_tokens = True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
